{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a13f6748-5150-4437-befb-614164649b63",
   "metadata": {},
   "source": [
    "# Working with Superphot+"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd57d8a-940f-4e1d-8283-1ffeae0f4394",
   "metadata": {},
   "source": [
    "Superphot+ was designed to rapidly fit photometric SN-like light curves to an empirical model for subsequent classification or analysis.\n",
    "This tutorial briefly covers how to import light curves directly from ALeRCE or ANTARES, apply pre-processing for improved quality, and run various sampling methods to fit the light curves."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fd62b8-c395-4a77-b690-ec865e2a4d7b",
   "metadata": {},
   "source": [
    "## Light curve import"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5056866-278a-4c2c-a4c0-9b999fbaf019",
   "metadata": {},
   "source": [
    "There are a suite of helper functions in `src/data_generation` to import photometric light curves from the ALeRCE or ANTARES servers. We will do both here to compare:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0949b9-b2b7-41b6-92c7-e3a4b25bde2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dustmaps.config import config\n",
    "\n",
    "config[\"data_dir\"] = \".\"  # ensure dustmaps path is correct\n",
    "\n",
    "# from superphot_plus.file_utils import read_single_lightcurve, save_single_lightcurve\n",
    "import os\n",
    "from superphot_plus.constants import *  # all hyperparameters/priors for fitting\n",
    "from superphot_plus.utils import *  # all utility functions\n",
    "from superphot_plus.import_utils import *\n",
    "from superphot_plus.data_generation.alerce import *\n",
    "from superphot_plus.data_generation.antares import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edfb90d-b5d4-4195-9f11-885c2754aefb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_sn = \"ZTF22abvdwik\"  # can change to any ZTF supernova"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fb542f-06b3-41d5-8f3f-c9caee951779",
   "metadata": {},
   "source": [
    "For this tutorial, we will save everything in `../examples/outputs/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b54272-40f4-4d44-9e26-a46dcd7a7d55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "OUTPUT_DIR = \"../examples/outputs/\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "generate_single_flux_file(test_sn, OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44314ca2-7cc8-41e6-a589-b4dde05f0c72",
   "metadata": {},
   "source": [
    "Great! Now let's extract and plot the lightcurve:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec8889f-1948-4220-8e26-7f2172ddcc10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "lc_fn = os.path.join(OUTPUT_DIR, test_sn + \".csv\")\n",
    "df = pd.read_csv(lc_fn)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1414fba6-182e-4a38-9530-5cc3fc850293",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "m = df[\"magpsf\"]  # magnitudes\n",
    "merr = df[\"sigmapsf\"]  # mag errs\n",
    "t = df[\"mjd\"]  # times\n",
    "b = df[\"fid\"] - 1  # alter so 0=g, 1=r\n",
    "\n",
    "plt.errorbar(t[b == 0], m[b == 0], yerr=merr[b == 0], fmt=\"o\", c=\"g\", label=\"g\")\n",
    "plt.errorbar(t[b == 1], m[b == 1], yerr=merr[b == 1], fmt=\"^\", c=\"r\", label=\"r\")\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel(\"MJD\")\n",
    "plt.ylabel(\"Apparent magnitude\")\n",
    "plt.gca().invert_yaxis()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56ce4ad-17c1-4361-adb3-17c95e62fe41",
   "metadata": {},
   "source": [
    "Because our fitting procedure assumes flux units instead of magnitude, we convert using an average zeropoint of 26.3. We also rule out any NaN values, sort the lightcurve, clip bogus LC tails, and apply extinction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75e7221-b857-4ea8-a253-82703b82497d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "t, f, ferr, b, ra, dec = import_lc(lc_fn)\n",
    "\n",
    "plt.close()\n",
    "plt.errorbar(t[b == \"g\"], f[b == \"g\"], yerr=ferr[b == \"g\"], fmt=\"o\", c=\"g\", label=\"g\")\n",
    "plt.errorbar(t[b == \"r\"], f[b == \"r\"], yerr=ferr[b == \"r\"], fmt=\"^\", c=\"r\", label=\"r\")\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel(\"MJD\")\n",
    "plt.ylabel(\"Flux (in arbitrary units)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa71ee4-46df-469a-8ac7-21cb2a02266b",
   "metadata": {},
   "source": [
    "We will then save these pre-processed lightcurves as a separate file to be input into the fitting scripts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c086ea2-b02a-4c9c-90af-cf5d48ae329d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from superphot_plus.lightcurve import Lightcurve\n",
    "\n",
    "lc = Lightcurve(\n",
    "    times=t,\n",
    "    fluxes=f,\n",
    "    flux_errors=ferr,\n",
    "    bands=b,\n",
    "    name=test_sn,\n",
    ")\n",
    "lc.save_to_file(\n",
    "    os.path.join(OUTPUT_DIR, test_sn+\".npz\"),\n",
    "    overwrite=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ab280b-d034-4840-945c-4d7c98c5bb02",
   "metadata": {},
   "source": [
    "## Fitting Light Curves"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e8d1af-484f-4f33-8c5a-c740d85e9e1c",
   "metadata": {},
   "source": [
    "There are a few sampling techniques implemented for rapid fitting of light curves:\n",
    "* Nested sampling (`dynesty`) constrains the posterior space with nested ellipsoids of increasing density.\n",
    "* Advanced HMC with the NUTS sampler (using `numpyro`) uses Hamiltonian Monte Carlo sampling but without U-turns to increase sampling efficiency.\n",
    "* Stochastic variational inference (SVI; also using `numpyro`) approximates the marginal distributions for each fit as Gaussians, which sacrifices precision for much faster runtime. Recommended for realtime applications.\n",
    "\n",
    "Let's use each to fit our test light curve:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9593ee13-8892-4798-9a35-59a7d8d3a8cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from superphot_plus.lightcurve import Lightcurve\n",
    "from superphot_plus.samplers.dynesty_sampler import DynestySampler\n",
    "from superphot_plus.samplers.numpyro_sampler import NumpyroSampler\n",
    "from superphot_plus.surveys.surveys import Survey\n",
    "\n",
    "fn_to_fit = os.path.join(OUTPUT_DIR, test_sn + \".npz\")\n",
    "lightcurve = Lightcurve.from_file(fn_to_fit)\n",
    "priors = Survey.ZTF().priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3edff38d-468c-45bc-8664-7d4dea566fee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "sampler = DynestySampler()\n",
    "posteriors = sampler.run_single_curve(lightcurve, priors=priors, rstate=np.random.default_rng(9876))\n",
    "posteriors.save_to_file(OUTPUT_DIR)\n",
    "print(\"Nested sampling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d764fdea-1863-4b75-8568-e5d903017ec9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "sampler = NumpyroSampler()\n",
    "posteriors = sampler.run_single_curve(lightcurve, priors=priors, rng_seed=1, sampler=\"NUTS\")\n",
    "posteriors.save_to_file(OUTPUT_DIR)\n",
    "print(\"NUTS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7300dc51-9c97-413f-9a7f-9b6747ce1d19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "sampler = NumpyroSampler()\n",
    "posteriors = sampler.run_single_curve(lightcurve, priors=priors, rng_seed=1, sampler=\"svi\")\n",
    "posteriors.save_to_file(OUTPUT_DIR)\n",
    "print(\"SVI\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e825f18b-aea8-4f41-8db2-89d75868c89a",
   "metadata": {},
   "source": [
    "Now, let's plot each fit to compare results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1f8c49-add8-4674-918a-5e3a50b9147a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from superphot_plus.plotting.lightcurves import plot_lc_fit\n",
    "from IPython import display\n",
    "from superphot_plus.surveys.surveys import Survey\n",
    "\n",
    "priors = Survey.ZTF().priors\n",
    "for method in [\"dynesty\", \"NUTS\", \"svi\"]:\n",
    "    plot_lc_fit(test_sn, priors.reference_band, priors.ordered_bands, OUTPUT_DIR, OUTPUT_DIR, OUTPUT_DIR, sampling_method=method, file_type=\"png\")\n",
    "\n",
    "display.Image(os.path.join(OUTPUT_DIR, test_sn + \"_dynesty.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2feefe2c-0c23-4217-9373-ddbca62091dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display.Image(os.path.join(OUTPUT_DIR, test_sn + \"_NUTS.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f991eabe-c5f5-42dc-bc24-b92b0f48bc5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display.Image(os.path.join(OUTPUT_DIR, test_sn + \"_svi.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15710919-15a0-4a2c-a450-5ae5f2b25366",
   "metadata": {},
   "source": [
    "It looks like there is a tradeoff between fit time and fit quality, though there may be an issues with priors. Plotting the distribution for our differing parameters ($t0$ and $\\gamma$), we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba16cc5-9047-4998-a0c3-874ebc8fa9b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from superphot_plus.file_utils import get_posterior_samples\n",
    "\n",
    "params_dynesty = get_posterior_samples(\n",
    "    test_sn, fits_dir=OUTPUT_DIR, sampler='dynesty'\n",
    ")[0]\n",
    "params_NUTS = get_posterior_samples(\n",
    "    test_sn, fits_dir=OUTPUT_DIR, sampler='NUTS'\n",
    ")[0]\n",
    "params_svi = get_posterior_samples(\n",
    "    test_sn, fits_dir=OUTPUT_DIR, sampler='svi'\n",
    ")[0]\n",
    "print(params_dynesty[0])\n",
    "\n",
    "t0_idx = 3\n",
    "gamma_idx = 2\n",
    "\n",
    "plt.hist(params_dynesty[:, t0_idx], alpha=0.5, label=\"dynesty\", density=True)\n",
    "plt.hist(params_NUTS[:, t0_idx], alpha=0.5, label=\"NUTS\", density=True)\n",
    "plt.hist(params_svi[:, t0_idx], alpha=0.5, label=\"SVI\", density=True)\n",
    "plt.xlabel(\"t0\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490f7464-f006-4d91-92ba-8b5d3ed2345f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from superphot_plus.surveys.surveys import Survey\n",
    "\n",
    "ztf_priors = Survey.ZTF().priors\n",
    "r_priors = ztf_priors.bands[\"r\"]\n",
    "PRIOR_GAMMA = r_priors.gamma\n",
    "\n",
    "plt.hist(params_dynesty[:, gamma_idx], alpha=0.5, label=\"dynesty\", density=True)\n",
    "plt.hist(params_NUTS[:, gamma_idx], alpha=0.5, label=\"NUTS\", density=True)\n",
    "plt.hist(params_svi[:, gamma_idx], alpha=0.5, label=\"SVI\", density=True)\n",
    "plt.axvline(PRIOR_GAMMA.mean, c=\"r\", label=\"Prior\")\n",
    "plt.axvline(PRIOR_GAMMA.mean + PRIOR_GAMMA.std, c=\"r\", linestyle=\"dashed\")\n",
    "plt.axvline(PRIOR_GAMMA.mean - PRIOR_GAMMA.std, c=\"r\", linestyle=\"dashed\")\n",
    "plt.xlabel(\"log gamma\")\n",
    "plt.xlim((0.5, 2))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceff99d2-ab2a-4186-a7f0-72c0fd3660e2",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fed51fa-cb23-4475-8b31-581b3c463501",
   "metadata": {},
   "source": [
    "Superphot+ uses the resulting fit parameters as input features for a multi-layer perceptron (MLP) classifier. We can call the classification functions to return probabilities of the object being each of 5 major supernova types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219ff968-cdcd-401c-ae07-dcb0808d26ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from superphot_plus.utils import adjust_log_dists\n",
    "from superphot_plus.trainer import SuperphotTrainer\n",
    "from superphot_plus.file_utils import get_posterior_samples\n",
    "\n",
    "TRAINED_MODEL_FN = os.path.join(OUTPUT_DIR, \"model.pt\")\n",
    "TRAINED_CONFIG_FN = os.path.join(OUTPUT_DIR, \"model.yaml\")\n",
    "trainer = SuperphotTrainer(\n",
    "    TRAINED_CONFIG_FN,\n",
    "    OUTPUT_DIR,\n",
    "    sampler=\"dynesty\",\n",
    "    model_type='MLP',\n",
    "    probs_file=None,\n",
    "    n_folds=1,\n",
    ")\n",
    "trainer.setup_model(load_checkpoint=True)\n",
    "lc_probs = trainer.classify_single_light_curve(\n",
    "    test_sn, OUTPUT_DIR, sampler=\"dynesty\"\n",
    ")\n",
    "print(lc_probs)\n",
    "# Alternatively, classify from posterior samples directly\n",
    "fit_params = get_posterior_samples(test_sn, OUTPUT_DIR, \"dynesty\")[0]\n",
    "adj_params = adjust_log_dists(fit_params)\n",
    "lc_probs2 = trainer.models[0].classify_from_fit_params(adj_params)\n",
    "print(np.subtract(lc_probs, np.mean(lc_probs2, axis=0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718e1bc7-a064-450c-aa24-68e5d70c5651",
   "metadata": {},
   "source": [
    "## Improvements that need to be made:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffaf39a-9917-46cd-a0f7-fcd95a76fd9f",
   "metadata": {},
   "source": [
    "* Exploration why variation between dynesty + numpyro fits\n",
    "* Quantifying minimum number of iters for SVI or warmup samples for NUTS for asymptotic fitting behavior\n",
    "* Modularizing numpyro script, removal of magic numbers\n",
    "* Refining plotting file, maybe splitting into separate folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b68b3a4-aa95-492d-a766-94dc2e012533",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multimodal_env2",
   "language": "python",
   "name": "multimodal_env2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "83afbb17b435d9bf8b0d0042367da76f26510da1c5781f0ff6e6c518eab621ec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
