{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing necessary libraries\n",
    "from mlflow_for_ml_dev.experiments.exp_utils import get_or_create_experiment\n",
    "\n",
    "# additional libraries\n",
    "import mlflow \n",
    "import random\n",
    "from typing import Dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"searching_for_runs\"\n",
    "tags = {\"project_name\":\"UNDEFINED\", \"topic\":\"searching\"}\n",
    "experiment = get_or_create_experiment(experiment_name, tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Demo Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_demo_run(run_name:str, experiment_id:str, run_tags:Dict[str,str]):\n",
    "    \"\"\"\n",
    "    Create a run with the given name, experiment_id and tags.\n",
    "\n",
    "    :param run_name: The name of the run\n",
    "    :param experiment_id: The id of the experiment\n",
    "    :param run_tags: The tags of the run\n",
    "    :return: The id of the run\n",
    "    \"\"\"\n",
    "    with mlflow.start_run(run_name=run_name, experiment_id=experiment_id, tags=run_tags) as run:\n",
    "        mlflow.log_params({\n",
    "            \"param1\": random.randint(0, 100),\n",
    "            \"param2\": random.randint(0, 100),\n",
    "            \"param3\": random.randint(0, 100)\n",
    "        })\t\n",
    "        mlflow.log_metrics({\n",
    "            \"metric1\": random.random(),\n",
    "            \"metric2\": random.random(),\n",
    "            \"metric3\": random.random()\n",
    "        })\n",
    "\n",
    "    return run.info.run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(100):\n",
    "    run_tags = {\"run_type\":random.choice([\"experiment\",\"optimization\"]),\"task\":random.choice([\"regression\",\"classification\"])}\n",
    "    run_name = random.choice([\"random_run\", \"important_run\"])\n",
    "    run_id = create_demo_run(\n",
    "        run_name = run_name,\n",
    "        experiment_id = experiment.experiment_id,\n",
    "        run_tags = run_tags\n",
    "    )\n",
    "    print(f\"Created run with id {run_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search Run Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "mlflow.search_runs(\n",
    "    experiment_ids: Optional[List[str]] = None,\n",
    "    filter_string: str = '',\n",
    "    run_view_type: int = 1,\n",
    "    max_results: int = 100000,\n",
    "    order_by: Optional[List[str]] = None,\n",
    "    output_format: str = 'pandas',\n",
    "    search_all_experiments: bool = False, \n",
    "    experiment_names: Optional[List[str]] = None\n",
    ") → Union[List[Run], pandas.DataFrame]\n",
    "```\n",
    "\n",
    "Search for Runs that fit the specified criteria.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = mlflow.search_runs(experiment_names=[\"searching_for_runs\"], search_all_experiments=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs[runs[\"tags.run_type\"] == \"optimization\"][[\"metrics.metric1\",\"metrics.metric2\",\"metrics.metric3\",\"tags.run_type\",\"tags.task\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using filter strings\n",
    "\n",
    "In order to filter your MLflow runs, you will need to write search queries, which are pseudo-SQL conditions expressed in a distinct syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = mlflow.search_runs(experiment_names=[\"searching_for_runs\"], filter_string=\"tags.run_type = 'optimization'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs[[\"metrics.metric1\",\"metrics.metric2\",\"metrics.metric3\",\"tags.run_type\",\"tags.task\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = mlflow.search_runs(experiment_names=[\"searching_for_runs\"], filter_string=\"tags.run_type = 'optimization' AND metrics.metric1 > 0.8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs[[\"metrics.metric1\",\"metrics.metric2\",\"metrics.metric3\",\"tags.run_type\",\"tags.task\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Returning Run Objects\n",
    "\n",
    "To return Run objects we have to specify this using the parameter `output_format`\n",
    "\n",
    "**output_format** – The output format to be returned. If pandas, a pandas.DataFrame is returned and, if list, a list of mlflow.entities.Run is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = mlflow.search_runs(experiment_names=[\"searching_for_runs\"], filter_string=\"tags.run_type = 'optimization'\", output_format=\"list\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for run in runs:\n",
    "    print(type(run))\n",
    "    print(f\"Name: {run.info.run_name}, ID: {run.info.run_id}, Metrics: {run.data.metrics}\")\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
