{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLflow Models:\n",
    "\n",
    "The mlflow.models module provides an API for saving machine learning models in “flavors” that can be understood by different downstream tools.\n",
    "\n",
    "## Sklearn Flavor\n",
    "\n",
    "The mlflow.sklearn module provides an API for logging and loading scikit-learn models. This module exports scikit-learn models with the following flavors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "import mlflow \n",
    "from mlflow.models.signature import infer_signature\n",
    "from mlflow_for_ml_dev.experiments.exp_utils import get_or_create_experiment \n",
    "from mlflow_for_ml_dev.experiments.exp_utils import get_root_project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create or get the experiment\n",
    "experiment_name = \"sklearn_models\"\n",
    "experiment = get_or_create_experiment(\n",
    "    experiment_name = experiment_name,\n",
    "    tags = {\n",
    "        \"proejct_name\": \"logging_models\",\n",
    "        \"topic\":\"run_management\",\n",
    "        \"mlflow.note.content\": \"This experiment is used to log sklearn models\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "\n",
    "with mlflow.start_run(run_name=\"basic_logging\", experiment_id=experiment.experiment_id):\n",
    "    # Log the model\n",
    "    mlflow.sklearn.log_model(sk_model=rfc, artifact_path = rfc.__class__.__name__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model With Signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the iris dataset\n",
    "iris = load_iris(as_frame=True)\n",
    "x = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# infer signature\n",
    "signature = infer_signature(model_input=x, model_output=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "\n",
    "with mlflow.start_run(run_name=\"logging_with_signature\", experiment_id=experiment.experiment_id):\n",
    "    # Log the model\n",
    "    mlflow.sklearn.log_model(sk_model=rfc, artifact_path = rfc.__class__.__name__, signature=signature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging with input example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a sample input\n",
    "input_example = x.iloc[0:10]\n",
    "print(input_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "\n",
    "with mlflow.start_run(run_name=\"logging_with_input_example\", experiment_id=experiment.experiment_id): \n",
    "    # Log the model\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model = rfc,\n",
    "        artifact_path = rfc.__class__.__name__,\n",
    "        signature = signature,\n",
    "        input_example = input_example\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging with code paths "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a sample input\n",
    "input_example = x.iloc[0:10]\n",
    "project_path = get_root_project()\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "with mlflow.start_run(run_name=\"logging_with_code_paths\", experiment_id=experiment.experiment_id):\n",
    "    # Log the model\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=rfc,\n",
    "        artifact_path = rfc.__class__.__name__,\n",
    "        signature=signature,\n",
    "        input_example=input_example,\n",
    "        code_paths=[(project_path / \"mlflow_for_ml_dev\").as_posix()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Registering the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "registered_model_name = \"iris_rfc\"\n",
    "\n",
    "# get a sample input\n",
    "input_example = x.iloc[0:10]\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "with mlflow.start_run(run_name=\"logging_and_registering\", experiment_id=experiment.experiment_id):\n",
    "\n",
    "    # Log the model\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=rfc,\n",
    "        artifact_path = rfc.__class__.__name__,\n",
    "        signature=signature,\n",
    "        input_example=input_example,\n",
    "        code_paths=[(project_path / \"mlflow_for_ml_dev\").as_posix()],\n",
    "        registered_model_name=registered_model_name\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:**\n",
    "----\n",
    " While it can be valid to wrap the entire code within the start_run block, this is not recommended. If there as in issue with the training of the model or any other portion of code that is unrelated to MLflow-related actions, an empty or partially-logged run will be created, which will necessitate manual cleanup of the invalid run. It is best to keep the training execution outside of the run context block to ensure that the loggable content (parameters, metrics, artifacts, and the model) are fully materialized prior to logging."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
