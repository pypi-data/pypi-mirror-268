public_npu_functions = ['npu_normalize_batch', 'npu_one_hot', 'npu_get_float_status', 'npu_fused_attention_score', 'npu_bert_apply_adam', 'npu_sign_bits_unpack', 'npu_indexing', 'npu_bounding_box_decode', 'npu_rotated_box_encode', 'npu_geglu', 'npu_ciou', 'npu_rotated_box_decode', 'npu_mish', 'npu_ifmr', 'npu_batch_nms', 'npu_conv_transpose2d', 'npu_multi_head_attention', 'npu_conv3d', 'npu_ffn', 'npu_dtype_cast', 'npu_transpose', 'npu_max', 'npu_mm_all_reduce_base', 'npu_clear_float_status', 'npu_rotated_iou', 'npu_swiglu', 'npu_scatter_nd_update_', 'npu_confusion_transpose', 'npu_stride_add', 'npu_convolution_transpose', 'fast_gelu', 'npu_alloc_float_status', 'npu_grid_assign_positive', 'npu_ptiou', 'npu_dropout_with_add_softmax', 'npu_scatter', 'npu_sign_bits_pack', 'npu_lstm', 'npu_gru', 'npu_anti_quant', '_npu_dropout', 'npu_scaled_masked_softmax', 'npu_linear', 'npu_fused_infer_attention_score', 'npu_nms_with_mask', 'npu_prompt_flash_attention', 'npu_weight_quant_batchmatmul', 'npu_format_cast', 'npu_conv2d', 'one_', 'npu_quant_matmul', 'npu_rotary_mul', 'npu_yolo_boxes_encode', 'npu_deformable_conv2d', 'npu_roi_align', 'npu_grouped_matmul', 'npu_silu', 'npu_quant_scatter', 'npu_min', 'npu_rotated_overlaps', 'empty_with_format', 'npu_rms_norm', 'npu_convolution', 'npu_format_cast_', 'npu_fusion_attention', 'npu_bounding_box_encode', 'npu_anchor_response_flags', 'npu_scatter_nd_update', 'npu_ps_roi_pooling', 'npu_random_choice_with_mask', 'npu_pad', 'npu_apply_adam', 'npu_reshape', 'copy_memory_', 'npu_giou', 'npu_masked_fill_range', 'npu_broadcast', 'npu_slice', 'npu_nms_v4', 'npu_bmmV2', 'npu_sort_v2', 'npu_softmax_cross_entropy_with_logits', 'npu_layer_norm_eval', 'npu_incre_flash_attention', 'npu_nms_rotated', 'npu_iou', 'npu_diou']